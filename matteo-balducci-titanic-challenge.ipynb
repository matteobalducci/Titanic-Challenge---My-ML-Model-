{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ntrain_data_path = '/kaggle/input/titanic/train.csv'\ntrain_data = pd.read_csv(train_data_path)\n\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T12:04:59.937247Z","iopub.execute_input":"2023-11-14T12:04:59.937678Z","iopub.status.idle":"2023-11-14T12:04:59.965752Z","shell.execute_reply.started":"2023-11-14T12:04:59.937644Z","shell.execute_reply":"2023-11-14T12:04:59.964524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set the aesthetics for the plots\nsns.set(style=\"whitegrid\")\n\n# Exploratory Data Analysis: Understanding the relationship of various features with Survival\n\n# Survival rate by Gender\nplt.figure(figsize=(10, 6))\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train_data)\nplt.title(\"Survival Rate by Gender\")\nplt.show()\n\n# Survival rate by Passenger Class\nplt.figure(figsize=(10, 6))\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train_data)\nplt.title(\"Survival Rate by Passenger Class\")\nplt.show()\n\n# Survival rate by Embarkation Port\nplt.figure(figsize=(10, 6))\nsns.barplot(x=\"Embarked\", y=\"Survived\", data=train_data)\nplt.title(\"Survival Rate by Embarkation Port\")\nplt.show()\n\n# Distribution of Age and its impact on Survival\nplt.figure(figsize=(10, 6))\nsns.histplot(data=train_data, x=\"Age\", hue=\"Survived\", kde=True, element=\"step\", stat=\"density\", common_norm=False)\nplt.title(\"Age Distribution and Survival\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T12:05:02.604909Z","iopub.execute_input":"2023-11-14T12:05:02.605572Z","iopub.status.idle":"2023-11-14T12:05:04.487497Z","shell.execute_reply.started":"2023-11-14T12:05:02.605527Z","shell.execute_reply":"2023-11-14T12:05:04.486140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Exploratory data analysis (EDA) of the Titanic dataset:\n\n\n1. **Survival Rate by Gender**: The first plot shows a higher survival rate for females compared to males. This suggests that gender could be a significant predictor of survival.\n\n2. **Survival Rate by Passenger Class (Pclass)**: The second plot indicates that passengers in the first class had a higher survival rate compared to those in the second and third classes. This suggests that socio-economic status, as indicated by the ticket class, may have played a role in survival chances.\n\n3. **Survival Rate by Embarkation Port**: The third plot illustrates variations in survival rates based on the port of embarkation. Passengers who embarked from Cherbourg (C) seem to have a higher survival rate compared to those from Queenstown (Q) and Southampton (S).\n\n4. **Age Distribution and Survival**: The last plot shows the age distribution of passengers and how it relates to survival. The plot indicates that younger passengers had a higher chance of survival compared to older passengers, with a notable peak in survival for children.\n\n\nBased on these insights, we can infer that gender, socio-economic status (Pclass), age, and possibly the port of embarkation could be important features for predicting survival. ","metadata":{}},{"cell_type":"code","source":"# Checking for missing values in the training data\nmissing_values = train_data.isnull().sum()\nmissing_values_percentage = (missing_values / len(train_data)) * 100\n\n# Displaying the count and percentage of missing values for each column\nmissing_data = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_values_percentage})\nmissing_data[missing_data['Missing Values'] > 0]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T12:05:09.843633Z","iopub.execute_input":"2023-11-14T12:05:09.844090Z","iopub.status.idle":"2023-11-14T12:05:09.860724Z","shell.execute_reply.started":"2023-11-14T12:05:09.844059Z","shell.execute_reply":"2023-11-14T12:05:09.859355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The analysis of missing values in the training data reveals the following:\n\n- **Age**: 177 missing values, constituting about 19.87% of the dataset.\n- **Cabin**: 687 missing values, which is a significant 77.10% of the dataset.\n- **Embarked**: 2 missing values, making up about 0.22% of the dataset.\n\nGiven this information, I handle missing values in the following way:\n\n1. **Age**: Since the percentage of missing values is significant but not overwhelming, we could impute these missing values. I choose to use the median age.\n\n2. **Cabin**: With 77.10% of the data missing, it might be challenging to impute this accurately, so I will drop it.\n\n3. **Embarked**: Only 2 values are missing. I impute these missing values with the mode of the 'Embarked' column.\n","metadata":{}},{"cell_type":"code","source":"# Handling missing values\n\n# Imputing missing values for Age with the median age\nmedian_age = train_data['Age'].median()\ntrain_data['Age'].fillna(median_age, inplace=True)\n\n# Dropping the Cabin column as it has a lot of missing values\ntrain_data.drop('Cabin', axis=1, inplace=True)\n\n# Imputing missing values for Embarked with the mode\nmode_embarked = train_data['Embarked'].mode()[0]\ntrain_data['Embarked'].fillna(mode_embarked, inplace=True)\n\n# Checking if all missing values have been addressed\ntrain_data.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T12:05:12.124702Z","iopub.execute_input":"2023-11-14T12:05:12.125154Z","iopub.status.idle":"2023-11-14T12:05:12.142166Z","shell.execute_reply.started":"2023-11-14T12:05:12.125120Z","shell.execute_reply":"2023-11-14T12:05:12.140766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All missing values in the dataset have now been addressed:\n\n- The missing values in the **Age** column have been filled with the median age.\n- The **Cabin** column, which had a large proportion of missing values, has been dropped.\n- The 2 missing values in the **Embarked** column have been filled with its mode (most common value).","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Re-importing the training data as the code execution state was reset\ntrain_data_path = '/kaggle/input/titanic/train.csv'\ntrain_data = pd.read_csv(train_data_path)\n\n# Imputing missing values for Age with the median age\nmedian_age = train_data['Age'].median()\ntrain_data['Age'].fillna(median_age, inplace=True)\n\n# Dropping the Cabin column as it has a lot of missing values\ntrain_data.drop('Cabin', axis=1, inplace=True)\n\n# Imputing missing values for Embarked with the mode\nmode_embarked = train_data['Embarked'].mode()[0]\ntrain_data['Embarked'].fillna(mode_embarked, inplace=True)\n\n# Encoding the 'Sex' column (male, female)\ntrain_data = pd.get_dummies(train_data, columns=['Sex'], drop_first=True)  # drop_first to avoid multicollinearity\n\n# Encoding the 'Embarked' column (C, Q, S)\ntrain_data = pd.get_dummies(train_data, columns=['Embarked'], drop_first=True)\n\n# Displaying the first few rows of the updated dataset to verify the changes\ntrain_data.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T12:05:14.538132Z","iopub.execute_input":"2023-11-14T12:05:14.538583Z","iopub.status.idle":"2023-11-14T12:05:14.577999Z","shell.execute_reply.started":"2023-11-14T12:05:14.538550Z","shell.execute_reply":"2023-11-14T12:05:14.576875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The categorical variables in the dataset have now been encoded:\n\n- The **Sex** column has been transformed into **Sex_male**, where 1 indicates male and 0 indicates female.\n- The **Embarked** column has been converted into two columns: **Embarked_Q** and `Embarked_S`, representing Queenstown and Southampton, respectively. The reference category (dropped to avoid multicollinearity) is Cherbourg.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# Instantiation of the basic models\nbase_rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\nbase_gb_model = GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=42)\nbase_xgb_model = XGBClassifier(n_estimators=50, max_depth=3, use_label_encoder=False, eval_metric='logloss', random_state=42)\n\n# Creation of the stacking ensemble model\nstacked_model = StackingClassifier(\n    estimators=[\n        ('random_forest', base_rf_model),\n        ('gradient_boosting', base_gb_model),\n        ('xgboost', base_xgb_model)\n    ],\n    final_estimator=LogisticRegression(),\n    cv=5\n)\n\n# Model evaluation with cross-validation\nstacked_cv_scores = cross_val_score(stacked_model, X_train, y_train, cv=5)\n\n# Calculation of the mean and standard deviation of the scores\nstacked_cv_mean = stacked_cv_scores.mean()\nstacked_cv_std = stacked_cv_scores.std()\n\nprint(f\"Average CV scores: {stacked_cv_mean}, Standard deviation: {stacked_cv_std}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T12:07:08.517159Z","iopub.execute_input":"2023-11-14T12:07:08.517681Z","iopub.status.idle":"2023-11-14T12:07:19.268571Z","shell.execute_reply.started":"2023-11-14T12:07:08.517642Z","shell.execute_reply":"2023-11-14T12:07:19.267623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load the Data\ntrain_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n\n# Handling missing values\ntrain_data['Age'].fillna(train_data['Age'].median(), inplace=True)\ntrain_data.drop('Cabin', axis=1, inplace=True)\ntrain_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace=True)\n\n# Coding of categorical variables\ntrain_data = pd.get_dummies(train_data, columns=['Sex', 'Embarked'], drop_first=True)\n\n# Definition of X and Y\nfeatures = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S']\nX = train_data[features]\ny = train_data['Survived']\n\n# Subdivision into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T12:08:36.698103Z","iopub.execute_input":"2023-11-14T12:08:36.698546Z","iopub.status.idle":"2023-11-14T12:08:36.726250Z","shell.execute_reply.started":"2023-11-14T12:08:36.698515Z","shell.execute_reply":"2023-11-14T12:08:36.725004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_model.fit(X_train, y_train)\n\n# Using the trained model to make predictions on the test dataset\ntest_data['Survived'] = stacked_model.predict(X_test)\n\nsubmission = test_data[['PassengerId', 'Survived']]\n\nsubmission_file_path = '/kaggle/working/submission.csv'\nsubmission.to_csv(submission_file_path, index=False)\n\nsubmission.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T12:08:39.474859Z","iopub.execute_input":"2023-11-14T12:08:39.475255Z","iopub.status.idle":"2023-11-14T12:08:41.685381Z","shell.execute_reply.started":"2023-11-14T12:08:39.475221Z","shell.execute_reply":"2023-11-14T12:08:41.684466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T12:12:28.001458Z","iopub.execute_input":"2023-11-14T12:12:28.001926Z","iopub.status.idle":"2023-11-14T12:12:28.020694Z","shell.execute_reply.started":"2023-11-14T12:12:28.001891Z","shell.execute_reply":"2023-11-14T12:12:28.019489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Caricamento del dataset di test\ntest_data_path = '/kaggle/input/titanic/test.csv'\ntest_data = pd.read_csv(test_data_path)\n\n# Preprocessing del dataset di test (simile a quello del dataset di training)\ntest_data['Age'].fillna(test_data['Age'].median(), inplace=True)\ntest_data['Fare'].fillna(test_data['Fare'].median(), inplace=True)  # Imputazione per 'Fare'\ntest_data = pd.get_dummies(test_data, columns=['Sex', 'Embarked'], drop_first=True)\n\n# Seleziona le stesse feature usate per l'allenamento del modello\nX_test = test_data[features]\n\n# Utilizza il modello allenato per fare previsioni sul dataset di test\ntest_data['Survived'] = stacked_model.predict(X_test)\n\n# Crea il DataFrame di submission\nsubmission = test_data[['PassengerId', 'Survived']]\n\n# Salva il DataFrame come file CSV\nsubmission_file_path = '/kaggle/working/submission.csv'\nsubmission.to_csv(submission_file_path, index=False)\n\n# Controlla le prime righe del file di submission\nsubmission.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T12:08:44.806463Z","iopub.execute_input":"2023-11-14T12:08:44.807553Z","iopub.status.idle":"2023-11-14T12:08:44.864016Z","shell.execute_reply.started":"2023-11-14T12:08:44.807511Z","shell.execute_reply":"2023-11-14T12:08:44.862843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I try to insert new engineering features for next ottimizing attemps\n\nimport pandas as pd\nimport numpy as np\n\n# Re-importing the training data for feature engineering\ntrain_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n\n# Feature Engineering\n# 1. Creating new features\n\n# Family Size - combination of SibSp and Parch\ntrain_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1  # Adding 1 for the passenger themselves\n\n# Age Categories - Binning Age into categories\nbins = [0, 12, 18, 60, np.inf]\nlabels = ['Child', 'Teenager', 'Adult', 'Senior']\ntrain_data['AgeCategory'] = pd.cut(train_data['Age'], bins, labels=labels, right=False)\n\n# Cabin Availability - whether the cabin information is available\ntrain_data['HasCabin'] = train_data['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n\n# 2. Preprocessing - handling missing values and encoding categorical variables\ntrain_data['Age'].fillna(train_data['Age'].median(), inplace=True)\ntrain_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace=True)\ntrain_data = pd.get_dummies(train_data, columns=['Sex', 'Embarked', 'AgeCategory'], drop_first=True)\n\n# Re-defining features and target variable with new features\nnew_features = features + ['FamilySize', 'HasCabin'] + [col for col in train_data.columns if 'AgeCategory' in col]\nX_new = train_data[new_features]\ny_new = train_data['Survived']\n\n# Splitting the data into training and validation sets for model training\nX_train_new, X_val_new, y_train_new, y_val_new = train_test_split(X_new, y_new, test_size=0.2, random_state=42)\n\n# Displaying the first few rows of the updated dataset with new features\nX_train_new.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T11:54:35.938693Z","iopub.execute_input":"2023-11-14T11:54:35.939091Z","iopub.status.idle":"2023-11-14T11:54:35.989231Z","shell.execute_reply.started":"2023-11-14T11:54:35.939060Z","shell.execute_reply":"2023-11-14T11:54:35.987842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset now includes the following features:\n\n- `Pclass`: Ticket class.\n- `Age`: Age of the passenger.\n- `SibSp`: Number of brothers/sisters or spouses on board.\n- `Park`: Number of parents or children on board.\n- `Do`: Ticket price.\n- `Sex_male`: Binary variable indicating male sex.\n- `Embarked_Q` and `Embarked_S`: Binary variables for ports of embarkation.\n- `FamilySize`: Family size (calculated as `SibSp` + `Parch` + 1).\n- `HasCabin`: Binary variable indicating whether the passenger has a cabin.\n- `AgeCategory_Teenager`, `AgeCategory_Adult`, `AgeCategory_Senior`: Binary variables for age categories.\n","metadata":{}}]}